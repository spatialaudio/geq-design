{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5a13f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "#HP Tuning\n",
    "from tensorboard.plugins.hparams import api as hp\n",
    "\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee7345ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22012, 31)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "InputData = np.loadtxt(\"Data/dataInputLarge.csv\",delimiter=\",\")\n",
    "OutputData = np.loadtxt (\"Data/dataOutputLarge.csv\", delimiter=\",\")\n",
    "\n",
    "InputDataSmall = np.loadtxt(\"Data/dataInput2.csv\",delimiter=\",\")\n",
    "OutputDataSmall = np.loadtxt (\"Data/dataOutput2.csv\", delimiter=\",\")\n",
    "\n",
    "InputDataLarge = np.loadtxt(\"Data/dataInputLarge2.csv\",delimiter=\",\")\n",
    "OutputDataLarge = np.loadtxt (\"Data/dataOutputLarge2.csv\", delimiter=\",\")\n",
    "\n",
    "InputDataLarge.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b0de1559",
   "metadata": {},
   "outputs": [],
   "source": [
    "InputDataTrain = InputData[0:9000]  \n",
    "InputDataTest = InputData[9000:11006]  \n",
    "OutputDataTrain = OutputData[0:9000] \n",
    "OutputDataTest = OutputData[9000:11006]\n",
    "\n",
    "InputDataTrainS = InputDataSmall[0:900]  \n",
    "InputDataTestS = InputDataSmall[900:1106]  \n",
    "OutputDataTrainS = OutputDataSmall[0:900] \n",
    "OutputDataTestS = OutputDataSmall[900:1106]\n",
    "\n",
    "InputDataTrainL = InputDataLarge[0:18000]  \n",
    "InputDataTestL = InputDataLarge[18000:22012]  \n",
    "OutputDataTrainL = OutputDataLarge[0:18000] \n",
    "OutputDataTestL = OutputDataLarge[18000:22012]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "48ca1eaa-249d-4e1d-9e81-9d9695d29110",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "InputDataTrain_transformed = scaler.fit_transform(InputDataTrain) \n",
    "#InputDataTrain_retransformed = scaler.inverse_transform(InputDataTrain_transformed)\n",
    "InputDataTest_transformed = scaler.fit_transform(InputDataTest)\n",
    "#InputDataTest_retransformed = scaler.inverse_transform(InputDataTest_transformed)\n",
    "OutputDataTrain_transformed = scaler.fit_transform(OutputDataTrain)\n",
    "#OutputDataTrain_retransformed = scaler.inverse_transform(OutputDataTrain_transformed)\n",
    "OutputDataTest_transformed = scaler.fit_transform(OutputDataTest)\n",
    "#OutputDataTest_retransformed = scaler.inverse_transform(OutputDataTest_transformed)         \n",
    "\n",
    "\n",
    "InputDataTrainS_transformed = scaler.fit_transform(InputDataTrainS) \n",
    "InputDataTestS_transformed = scaler.fit_transform(InputDataTestS)\n",
    "OutputDataTrainS_transformed = scaler.fit_transform(OutputDataTrainS)\n",
    "OutputDataTestS_transformed = scaler.fit_transform(OutputDataTestS)\n",
    "\n",
    "InputDataTrainL_transformed = scaler.fit_transform(InputDataTrainL) \n",
    "InputDataTestL_transformed = scaler.fit_transform(InputDataTestL)\n",
    "InputDataTestL_retransformed = scaler.inverse_transform(InputDataTestL_transformed)\n",
    "OutputDataTrainL_transformed = scaler.fit_transform(OutputDataTrainL)\n",
    "OutputDataTestL_transformed = scaler.fit_transform(OutputDataTestL)\n",
    "OutputDataTestL_retransformed = scaler.inverse_transform(OutputDataTestL_transformed)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "190f40b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model() :\n",
    "    return tf.keras.models.Sequential([\n",
    "      tf.keras.layers.Dense(62,input_shape = (31,),activation='relu'),\n",
    "      tf.keras.layers.Dense(31,activation=\"linear\"),\n",
    "      tf.keras.layers.Dense(31,activation=\"linear\"),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "2652e4d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "modelName =\"Model\"\n",
    "#modelName =\"ModelLarge\"\n",
    "\n",
    "model_load = tf.keras.models.load_model(\"Models/\"+modelName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6a55ede1-d5ce-428d-a356-fc9683d1b1c4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = create_model()\n",
    "#model = model_load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "fab4170c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_12 (Dense)             (None, 62)                1984      \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 31)                1953      \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 31)                992       \n",
      "=================================================================\n",
      "Total params: 4,929\n",
      "Trainable params: 4,929\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, 31)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.summary()\n",
    "model.output_shape\n",
    "#model.layers[1].get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "fd534e56-7280-4270-9d4a-777a2b3c2803",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.MeanSquaredError(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "f46d4642-65ad-477e-be50-7099f423423a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x142630d5730>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=InputDataTrain_transformed, \n",
    "          y=OutputDataTrain_transformed, \n",
    "          epochs=2000,\n",
    "          batch_size = 500,\n",
    "          validation_data=(InputDataTest_transformed, OutputDataTest_transformed), \n",
    "          verbose = 0,\n",
    "          #callbacks=[tensorboard_callback]\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "a637ce61-ec4e-423d-98e1-c6d8f0376eb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 1/63 [..............................] - ETA: 0s - loss: 3.8568e-05 - accuracy: 0.9375\n",
      "63/63 [==============================] - 0s 546us/step - loss: 1.2851e-04 - accuracy: 0.8210\n",
      "Test loss, Test acc: [0.00012851030624005944, 0.8210368752479553]\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(InputDataTest_transformed,OutputDataTest_transformed)\n",
    "print(\"Test loss, Test acc:\", results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "b5e82ac6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x14263441400>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=InputDataTrainS_transformed, \n",
    "          y=OutputDataTrainS_transformed, \n",
    "          epochs=1000,\n",
    "          batch_size = 50,\n",
    "          validation_data=(InputDataTestS_transformed, OutputDataTestS_transformed), \n",
    "          verbose = 0,\n",
    "          #callbacks=[tensorboard_callback]\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "0023f95a-85b5-444f-98b0-a55b6295033f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 1/63 [..............................] - ETA: 0s - loss: 1.0225e-04 - accuracy: 0.9062\n",
      "63/63 [==============================] - 0s 533us/step - loss: 3.6685e-04 - accuracy: 0.7906\n",
      "Test loss, Test acc: [0.0003668488934636116, 0.7906281352043152]\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(InputDataTest_transformed,OutputDataTest_transformed)\n",
    "print(\"Test loss, Test acc:\", results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "ec5631fa-c8eb-488c-8707-9b46feba9753",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x14263ab4af0>"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=InputDataTrainL_transformed, \n",
    "          y=OutputDataTrainL_transformed, \n",
    "          epochs=1000,\n",
    "          batch_size = 500,\n",
    "          validation_data=(InputDataTestL_transformed, OutputDataTestL_transformed), \n",
    "          verbose = 0,\n",
    "          #callbacks=[tensorboard_callback]\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "4119d525-751b-4556-ac09-e06eca02ff7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 1/63 [..............................] - ETA: 0s - loss: 4.0116e-05 - accuracy: 0.9688\n",
      "63/63 [==============================] - 0s 540us/step - loss: 1.0869e-04 - accuracy: 0.8400\n",
      "Test loss, Test acc: [0.0001086904012481682, 0.8399800658226013]\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(InputDataTest_transformed,OutputDataTest_transformed)\n",
    "print(\"Test loss, Test acc:\", results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca017ff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %tensorboard --logdir logs --host localhost --port 6003"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6fff2461-d96e-4c20-bffd-9fac9608efe3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%run Code.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2df3dc7e-0d34-4ff9-86eb-365d132aa45d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions shape: (1, 31)\n",
      "InputDataTest: [[1. 0. 0. 0. 1. 1. 1. 0. 0. 0. 1. 1. 1. 0. 0. 0. 1. 1. 1. 0. 0. 0. 1. 1.\n",
      "  1. 0. 0. 0. 1. 1. 1.]]\n",
      "InputDataTest in db (Command Gains) [[ 12. -12. -12. -12.  12.  12.  12. -12. -12. -12.  12.  12.  12. -12.\n",
      "  -12. -12.  12.  12.  12. -12. -12. -12.  12.  12.  12. -12. -12. -12.\n",
      "   12.  12.  12.]]\n",
      "OutputDataTest: [[0.9869313  0.20718894 0.38389808 0.2095621  0.7919994  0.61294599\n",
      "  0.79155865 0.20641607 0.38570965 0.20395545 0.79498765 0.61140999\n",
      "  0.79346564 0.20603459 0.3879075  0.2043642  0.79174284 0.61200254\n",
      "  0.79551196 0.20753682 0.39186006 0.20873104 0.78956493 0.60907287\n",
      "  0.79414958 0.21403475 0.37751776 0.1875827  0.76116584 0.63324487\n",
      "  0.91571561]]\n",
      "Predictions: [[0.9795226  0.20193663 0.3901816  0.21714607 0.7914475  0.6133987\n",
      "  0.7894629  0.20715857 0.38685867 0.2101132  0.79404944 0.6060786\n",
      "  0.7903979  0.20671436 0.39209005 0.20991397 0.7884521  0.6078596\n",
      "  0.79399234 0.20538858 0.39323336 0.20413297 0.78875446 0.60546803\n",
      "  0.79615676 0.21120936 0.38131782 0.19071743 0.7611301  0.63340634\n",
      "  0.9132066 ]]\n",
      "OutputDataTest in dB: [[ 19.40677225 -15.96981603  -6.35562511 -16.10242858  16.01468431\n",
      "    6.12539447  16.05917527 -16.07512075  -6.14991993 -16.08031974\n",
      "   16.07453046   6.14383476  16.06073086 -16.05973027  -6.14357186\n",
      "  -16.076621    16.06086348   6.14439671  16.10946545 -16.06261721\n",
      "   -6.14009477 -16.17636632  15.94673397   6.04782743  16.13384615\n",
      "  -15.76015536  -6.54692207 -16.49223958  13.4026634    6.08925683\n",
      "   11.84168258]]\n",
      "Predictions in dB [[ 19.111595  -16.255917   -6.0120263 -15.684561   15.984373    6.150171\n",
      "   15.944518  -16.034388   -6.0868645 -15.744114   16.02294     5.852043\n",
      "   15.892224  -16.022501   -5.9130535 -15.774337   15.879817    5.915213\n",
      "   16.026644  -16.180628   -6.0644636 -16.431753   15.902018    5.8476467\n",
      "   16.244183  -15.915437   -6.344143  -16.326881   13.400831    6.096636\n",
      "   11.770212 ]]\n",
      "Diff: [[ 0.2951771   0.28610057 -0.3435988  -0.4178678   0.03031122 -0.02477633\n",
      "   0.11465718 -0.04073316 -0.06305546 -0.33620582  0.05159078  0.29179161\n",
      "   0.16850654 -0.03722928 -0.23051834 -0.30228419  0.18104647  0.2291836\n",
      "   0.0828217   0.11801061 -0.07563115  0.25538684  0.04471637  0.20018072\n",
      "  -0.11033643  0.15528139 -0.20277916 -0.16535817  0.00183218 -0.00737899\n",
      "   0.07147041]]\n"
     ]
    }
   ],
   "source": [
    "first = 4010\n",
    "second = 4011\n",
    "\n",
    "predictions = model.predict(InputDataTestL_transformed[first:second])\n",
    "print(\"predictions shape:\", predictions.shape)\n",
    "print(\"InputDataTest:\",InputDataTestL_transformed[first:second])\n",
    "print(\"InputDataTest in db (Command Gains)\", InputDataTestL_retransformed[first:second])\n",
    "print(\"OutputDataTest:\",OutputDataTestL_transformed[first:second])\n",
    "print(\"Predictions:\",predictions)\n",
    "\n",
    "print(\"OutputDataTest in dB:\",scaler.inverse_transform(OutputDataTestL_transformed[first:second]))\n",
    "print(\"Predictions in dB\",scaler.inverse_transform(predictions))\n",
    "\n",
    "print(\"Diff:\", scaler.inverse_transform(OutputDataTestL_transformed[first:second])-scaler.inverse_transform(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "61418cd9-4702-4569-9fed-77dec144822e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "commandGains = InputDataTestL_retransformed[first:second].reshape((31,1)) \n",
    "#print(commandGains)\n",
    "filterGainsPredicted = scaler.inverse_transform(predictions).reshape((31,1)) \n",
    "#print(filterGainsPredicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fc43973c-59f1-4a54-bfaa-634bb5e301db",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:/Users/Robert/AppData/Local/Temp/xpython_14936/1534437943.py:52: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  Gopt_db = np.linalg.lstsq(leak.conj().T, G_db2)[0]\n",
      "C:/Users/Robert/AppData/Local/Temp/xpython_14936/4126492185.py:34: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  num = np.array([(1+G*beta), -2*cos(w0), (1-G*beta)]/(1+beta))\n",
      "C:/Users/Robert/AppData/Local/Temp/xpython_14936/4126492185.py:35: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  den = np.array([1, -2*cos(w0)/(1+beta), (1-beta)/(1+beta)])\n",
      "C:/Users/Robert/AppData/Local/Temp/xpython_14936/1534437943.py:56: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  G2opt_db = np.linalg.lstsq(leak2.conj().T, G_db2)[0] #filter gains\n",
      "C:/Users/Robert/AppData/Local/Temp/xpython_14936/4126492185.py:34: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  num = np.array([(1+G*beta), -2*cos(w0), (1-G*beta)]/(1+beta))\n",
      "C:/Users/Robert/AppData/Local/Temp/xpython_14936/4126492185.py:35: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  den = np.array([1, -2*cos(w0)/(1+beta), (1-beta)/(1+beta)])\n"
     ]
    }
   ],
   "source": [
    "thirdOctaveGEQwithPredictions(commandGains,filterGainsPredicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e6b46bc9-ee07-4431-8b0c-c9f49d2a0f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"Models/\"+modelName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca9b0a8-8a94-4f79-9dbd-43291fe4c3cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 (XPython)",
   "language": "python",
   "name": "xpython"
  },
  "language_info": {
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
